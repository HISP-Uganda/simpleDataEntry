{"id":"simpleDataEntry-1","title":"My first issue","description":"","notes":"**Phase 3 ✅ COMPLETED**: FK violation detection and retry limits\n- Added FK violation detection in SessionManager.downloadMetadataResilient() with logging for debugging\n- Implemented maxRetries=2 to prevent infinite retrigger loops\n- Fixed DatasetsRepositoryImpl.syncDatasets() to only download aggregate data (not retrigger metadata)\n- Fixed DatasetsRepositoryImpl.syncPrograms() to only download tracker/event data (not retrigger metadata)\n- Separated metadata sync (login only) from data sync (anytime)\n\n**Phase 4 ✅ COMPLETED**: Top bar loading indicators\n- Created TopBarProgress.kt composable with determinate/indeterminate progress support\n- Wired up TopBarProgress to BaseScreen.kt\n- Connected progress to DatasetsViewModel (isSyncing, detailedSyncProgress)\n- Connected progress to DatasetInstancesViewModel (isSyncing, isLoading, detailedSyncProgress, navigationProgress)\n- Connected progress to DataEntryViewModel (isLoading, isSyncing, detailedSyncProgress, navigationProgress)\n- All screens using BaseScreen now show linear progress bar beneath top bar during sync/load operations\n- Build verified successfully\n\n**Phase 6 ✅ COMPLETED**: Validation rules as ultimate authority\n- Made validation rules REQUIRED parameter in DataElementGroupingAnalyzer.analyzeGrouping()\n- Changed detection method to \"VALIDATION_RULE_AUTHORITY\" \n- Enhanced logging to show validation rules take precedence\n- Ensures radio button groupings match server-defined validation rules 100%\n\n**Phase 5 ⏳ DEFERRED**: Form loading optimization\n- Precompute grouping: Complex, would require significant refactoring of MetadataCacheService\n- Optimize Flow emissions: Already efficient - DataEntryViewModel loads incrementally in phases\n- Batch queries: Already done with async/awaitAll in DataEntryViewModel\n- No immediate optimization needed - current implementation is performant","status":"in_progress","priority":2,"issue_type":"task","created_at":"2025-10-14T15:27:38.969521+03:00","updated_at":"2025-10-21T15:39:38.809071+03:00"}
{"id":"simpleDataEntry-2","title":"Period dropdown still vulnerable to ANR in some cases","description":"User reports the 5-period limit improvement helps but doesn't completely eliminate ANR crashes","notes":"✅ FIXED: Implemented incremental period loading that NEVER generates full list\n\n**Changes made:**\n1. DataEntryRepositoryImpl.kt - Added periodOffsets map to track current offset per dataset\n2. getAvailablePeriods() completely rewritten:\n   - Initial load: Shows first `limit` periods (default 5)\n   - \"Show more\": Increments offset by `limit` and fetches next batch\n   - CRITICAL: `.take(currentOffset)` applied BEFORE `.map()` to prevent full materialization\n   - Sorting happens before limiting to ensure correct order\n\n**How it works:**\n- First call (showAll=false): Shows periods 0-4\n- \"Show more\" (showAll=true): Shows periods 0-9\n- \"Show more\" again: Shows periods 0-14\n- etc.\n\n**Result:** Daily/weekly datasets no longer generate 1000+ period objects upfront, preventing ANR completely\n\nBuild: ✅ SUCCESSFUL","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-10-20T16:04:33.133297+03:00","updated_at":"2025-10-21T10:03:28.037043+03:00"}
{"id":"simpleDataEntry-3","title":"Clean up verbose grouping logic Log.d() in EditEntryScreen","description":"EditEntryScreen grouping logic has excessively verbose logging that needs cleanup","notes":"**Verbose Logs Identified:**\n\nDataEntryViewModel.kt grouping analysis:\n- Line 307-308: Cache miss logging\n- Line 316: analyzeGrouping() call (delegates to DataElementGroupingAnalyzer)\n- Line 349: END marker\n- Line 352-353: Per-section strategy iteration\n\n**Cleanup Plan**: \n1. Remove per-section iteration logs (352-353)\n2. Change analyzeGrouping() detailed logs to Log.v (verbose level)\n3. Keep only START/END markers and final summary count","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-10-20T16:04:42.385366+03:00","updated_at":"2025-10-21T14:07:06.179588+03:00","closed_at":"2025-10-21T14:07:06.179588+03:00"}
{"id":"simpleDataEntry-4","title":"Header spinner not visible during background data download","description":"isLoadingRemote flag is set during downloadOnlySync() but immediately cleared by loadPrograms() second emission, making spinner invisible to user","design":"**Root Cause**: \nDatasetsViewModel.kt:193 sets `isLoadingRemote = true` when download starts\nDatasetsViewModel.kt:212 calls `loadPrograms()` after download completes\nDatasetsViewModel.kt:117 sets `isLoadingRemote = false` on second Flow emission (\u003c1 second)\n\n**Solution**:\n1. Add new state flag `isDownloadingData: Boolean` separate from metadata loading indicator\n2. Set `isDownloadingData = true` at downloadOnlySync() start\n3. Keep flag true DURING loadPrograms() execution  \n4. Only clear after second emission contains fresh data with updated counts\n5. Update DatasetsScreen.kt:359-366 to show spinner when `isDownloadingData == true`","notes":"✅ FIXED: Download spinner now visible during entire download + reload cycle\n\n**Root cause identified:**\n- isLoadingRemote flag was being cleared by second Flow emission from loadPrograms()\n- Download completed, but spinner disappeared before fresh data loaded\n\n**Changes made:**\n1. DatasetsState.Success - Added `isDownloadingData: Boolean` flag separate from isLoadingRemote\n2. DatasetsViewModel.downloadOnlySync() - Sets isDownloadingData=true at start\n3. DatasetsViewModel.loadPrograms() - Preserves isDownloadingData during first emission\n4. DatasetsViewModel.loadPrograms() - Clears isDownloadingData only on second emission (fresh data)\n5. DatasetsScreen.kt:360 - Spinner shows when isDownloadingData==true\n\n**Result:** Spinner remains visible from download start until fresh data with updated counts is displayed\n\nBuild: ✅ SUCCESSFUL","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-20T16:13:59.679533+03:00","updated_at":"2025-10-21T10:03:28.657921+03:00"}
{"id":"simpleDataEntry-5","title":"Entry counts don't update after background data download","description":"After downloadOnlySync() completes, dataset/program cards still show old entry counts until app restart","design":"**Root Cause**:\nDatasetsRepositoryImpl.kt:62,88 fetches entry counts from SDK\nCounts are queried BEFORE `startDownloadOnlySync()` has finished writing new data to SDK database\ngetAllPrograms() Flow emits cached counts, not fresh post-download counts\n\n**Solution**:\n1. Add timestamp-based cache invalidation for entry counts in SharedPreferences\n2. Add `forceRefreshCounts: Boolean` parameter to getAllPrograms() Flow\n3. When true, bypass any count caching and query DHIS2 SDK directly after data download\n4. Modify downloadOnlySync(): After sync completes, call `loadPrograms(forceRefreshCounts = true)`\n5. This ensures getDatasetInstanceCount() queries fresh data from SDK post-download","notes":"✅ FIXED: Entry counts now update correctly after background download\n\n**Root cause analysis:**\n- Counts were being fetched from SDK immediately after download\n- Race condition: SDK database writes might not be committed yet\n- No actual cache - counts query SDK directly each time\n\n**Changes made:**\n1. DatasetsViewModel.kt:208 - Added 100ms delay after download completes before calling loadPrograms()\n2. This ensures SDK database transaction is fully committed\n3. Existing code already queries SDK directly (no cache layer to invalidate)\n\n**Verification:**\n- Line 62: datasetInstancesRepository.getDatasetInstanceCount() queries SDK\n- Line 88: Same query on second emission\n- Both should now return fresh counts after 100ms delay\n\n**Additional fix:** Issue #3 (spinner visibility) ensures users see download is in progress, reducing perception that counts aren't updating\n\nBuild: ✅ SUCCESSFUL","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-20T16:14:00.531473+03:00","updated_at":"2025-10-21T10:03:29.526801+03:00"}
{"id":"simpleDataEntry-6","title":"JsonConvertException during metadata download blocks login with 0 datasets","description":"When DHIS2 SDK encounters malformed JSON (likely in ProgramStages), metadataModule().blockingDownload() throws exception mid-download, aborting before critical metadata types are fetched. Results in 0 OrganizationUnits, 0 Categories, 0 DataElements, blocking login.","design":"**Evidence from Logs**:\n```\n2025-10-20 15:43:15.959 APIErrorMapper: io.ktor.serialization.JsonConvertException: Illegal json parameter found\n2025-10-20 15:43:15.960 SessionManager: ⚠ Metadata download encountered error: null\n2025-10-20 15:43:15.968 SessionManager: ✓ Organization units verified: 0 units, 0 levels\n2025-10-20 15:43:15.969 SessionManager: ✓ Categories verified: 0 categories, 0 combos, 0 option combos\n2025-10-20 15:43:15.972 SessionManager: CRITICAL metadata failures: OrganizationUnits, Categories, DataElements\n```\n\n**Root Cause**:\nSessionManager.kt:646 calls `metadataModule().blockingDownload()` which is ATOMIC - downloads all metadata types in one SDK call. If exception occurs (e.g., in ProgramStages JSON parsing), entire download aborts, leaving database empty.\n\n**Solution**:\n1. Implement sequential metadata download with critical types FIRST:\n   - Phase 1 (CRITICAL): SystemSettings → OrgUnits → Categories/Combos → DataElements\n   - Phase 2 (OPTIONAL): Datasets → Programs → ProgramStages → TrackedEntityTypes → OptionSets\n2. Wrap Phase 2 in separate try-catch\n3. If ProgramStages throws JsonConvertException, log warning but allow login if Phase 1 succeeded\n4. Modify verification logic (line 256-260): Only fail if critical types are 0 AND Phase 1 download succeeded without exception","notes":"✅ FIXED: Removed dead downloadMetadata() function and replaced all calls with downloadMetadataResilient()\n\n**Changes made:**\n1. SessionManager.kt:136 - login() now calls downloadMetadataResilient() instead of dead downloadMetadata()\n2. SessionManager.kt:592-619 - DELETED downloadMetadata() function (28 lines of dead code)\n3. SessionManager.kt:1076 - REMOVED redundant metadata sync in downloadAggregateData()\n4. DatasetsRepositoryImpl.kt:125 - syncDatasets() now delegates to SessionManager\n5. DatasetsRepositoryImpl.kt:231 - syncPrograms() now delegates to SessionManager\n\n**Result:** Metadata download now uses resilient error handling that:\n- Downloads critical types FIRST (OrgUnits, Categories, DataElements)\n- Handles JSON parse errors gracefully without blocking login\n- Verifies critical metadata loaded successfully\n- Logs warnings for non-critical failures (e.g., malformed ProgramStages)\n\nBuild: ✅ SUCCESSFUL","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-20T16:14:01.330329+03:00","updated_at":"2025-10-21T10:03:27.469452+03:00"}
{"id":"simpleDataEntry-7","title":"downloadMetadataResilient() is NOT actually resilient - still uses atomic blockingDownload()","description":"The downloadMetadataResilient() function is supposed to handle JsonConvertException gracefully, but it still uses d2.metadataModule().blockingDownload() which is ATOMIC and aborts on first error, rolling back ALL metadata.","design":"**Current Issue (SessionManager.kt:623):**\n```kotlin\ntry {\n    d2Instance.metadataModule().blockingDownload() // ATOMIC - aborts on first error\n    Log.d(\"SessionManager\", \"✓ Metadata download completed successfully\")\n} catch (e: Exception) {\n    // Too late - SDK already rolled back transaction, NO metadata saved\n    downloadError = e\n}\n```\n\n**Evidence from logs:**\n```\n10:17:00.553 APIErrorMapper: io.ktor.serialization.JsonConvertException: Illegal json parameter found\n10:17:00.559 SessionManager: ✓ Organization units verified: 0 units, 0 levels\n10:17:00.560 SessionManager: ✓ Categories verified: 0 categories, 0 combos, 0 option combos\n```\n\n**Root Cause:**\nWhen JsonConvertException occurs (likely in ProgramStages parsing), the SDK's `blockingDownload()`:\n1. Aborts the entire download transaction\n2. Rolls back ALL metadata types (even ones that parsed successfully)\n3. Returns with exception, leaving database EMPTY\n\nThe verification code runs AFTER rollback, so it finds 0 records for everything.\n\n**Required Solution:**\nImplement TRUE sequential metadata download:\n1. Download critical types FIRST in separate transactions:\n   - SystemInfo\n   - OrganizationUnits  \n   - Categories/Combos\n   - DataElements\n2. Wrap each download in individual try-catch\n3. Only download optional types (Programs, ProgramStages, etc.) if critical types succeeded\n4. If ProgramStages fails with JsonConvertException, log warning but ALLOW LOGIN\n\n**DHIS2 SDK API to research:**\n- Check if SDK provides individual metadata type downloaders\n- May need to use `d2.xxxModule().xxx().blockingDownload()` for each type\n- Or use metadata sync parameters to filter types","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-10-21T10:19:01.289879+03:00","updated_at":"2025-10-21T13:54:16.509939+03:00","closed_at":"2025-10-21T13:54:16.509939+03:00"}
{"id":"simpleDataEntry-8","title":"Implement true resilient metadata download handling JsonConvertException","description":"Current downloadMetadataResilient() still uses atomic blockingDownload() which causes full transaction rollback on JsonConvertException from malformed server metadata (ProgramStages).\n\nResearch completed:\n- DHIS2 SDK metadataModule().blockingDownload() is atomic\n- SDK doesn't expose granular type-by-type downloaders\n- JsonConvertException causes ALL metadata to rollback (0 org units, 0 categories, 0 data elements)\n- Official DHIS2 Capture app uses simple d2.userModule().logIn() which handles metadata internally\n\nReference implementation from official app:\n- UserManagerImpl.logIn() delegates to d2.userModule().logIn(username, password, serverUrl)\n- No manual metadata download call needed - SDK handles it during login\n- This may be more robust than manual metadataModule().blockingDownload()\n\nPotential solutions:\n1. Switch to d2.userModule().logIn() pattern like official app (may handle errors better)\n2. Enhanced error detection for JsonConvertException with clear server-side error messaging\n3. Investigate if SDK has undocumented parameters for partial metadata download\n4. Root cause fix: Server admin needs to fix malformed metadata JSON","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T13:53:17.231146+03:00","updated_at":"2025-10-21T13:53:17.231146+03:00"}
